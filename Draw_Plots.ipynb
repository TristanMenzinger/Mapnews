{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geoplot\n",
    "from shapely.geometry import Point, Polygon\n",
    "import os\n",
    "import pytz\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import spacy\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we can use LATEX in Matplotlib/Geoplot/Geopandas plots\n",
    "plt.rcParams['text.usetex']=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spacy nlp model for keyword extraction \n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all .json files saved in two hour intervals \n",
    "news_files_paths = [\"Data/{}\".format(f) for f in os.listdir(\"Mapnews-Data\") if \".json\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From geopandas, get the countries outlines\n",
    "world = gpd.read_file(\n",
    "    gpd.datasets.get_path('naturalearth_lowres')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    \"\"\" Read a json news file from a given path \"\"\"\n",
    "    f = open(path)\n",
    "    data = f.read()\n",
    "    f.close()\n",
    "    return json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(data):\n",
    "    \"\"\" Parse the news data into a useful geodataframe and return it \"\"\"\n",
    "    \n",
    "    # Extract all information\n",
    "    # - title\n",
    "    # - date\n",
    "    # - locations\n",
    "    all_info = []\n",
    "    for d in data:\n",
    "        info = []\n",
    "        for l in d[\"geolocations\"]:\n",
    "            info += [\n",
    "                {\n",
    "                    \"title\": d[\"title\"],\n",
    "                    \"date\": d[\"published\"],\n",
    "                    **l\n",
    "                }\n",
    "            ]\n",
    "        all_info.extend(info)\n",
    "    \n",
    "    # Create the dataframe\n",
    "    df = gpd.GeoDataFrame(all_info)\n",
    "    \n",
    "    # Convert to geometry\n",
    "    df[\"geometry\"] = df.apply(lambda x: Point(x.lng, x.lat), axis=1)\n",
    "    df = df.rename(columns={\"type\": \"loc_type\"})\n",
    "    \n",
    "    # Create a proper date and add a date_hour column for hourly grouping\n",
    "    df.date = pd.to_datetime(df.date, errors=\"coerce\")\n",
    "    df.date = df.date.apply(lambda x: x.astimezone(pytz.utc))\n",
    "    df[\"date_hour\"] = pd.to_numeric(df.date.dt.strftime(\"%H\"))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords(text):\n",
    "    \"\"\" Get the keywords from a given text using \"\"\"\n",
    "    result = []\n",
    "    pos_tag = ['PROPN', 'ADJ', 'NOUN']\n",
    "    doc = nlp(text.lower())\n",
    "    for token in doc:\n",
    "        if(token.text in nlp.Defaults.stop_words or token.text in punctuation):\n",
    "            continue\n",
    "        if(token.pos_ in pos_tag):\n",
    "            result.append(token.text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_10_locations(data_hb):\n",
    "    \"\"\" Get the top 10 locations from a block of data / the news' locations \"\"\"\n",
    "    top_10_loc = data_hb.groupby(\"name\")[\"count\"].sum().sort_values(ascending=False)\n",
    "    top_10_loc_text = list(top_10_loc[:10].index)\n",
    "    return top_10_loc_text, list(top_10_loc[:10].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not used (yet)\n",
    "whitelist = set('abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "def get_top_10_keywords(data_hb):\n",
    "    \"\"\" Get the top 10 keywords from a block of data / the news' titles \"\"\"\n",
    "    titles_clean = data_hb.title.apply(lambda x: ''.join(filter(whitelist.__contains__, x)))\n",
    "    titles_clean = \" \".join(list(titles_clean))\n",
    "    top_words = get_hotwords(titles_clean)\n",
    "    top_10_keywords = [i[0].title() for i in Counter(top_words).most_common(10)]\n",
    "    counts = [i[1] for i in Counter(top_words).most_common(10)]\n",
    "    return top_10_keywords, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To keep the plot from adjusting the viewport to the coordinates \n",
    "# of the news, a dummy outline is added every time\n",
    "p = Polygon([[-250, -150], [250, -150], [250, 150], [-250, 150]])\n",
    "outline = gpd.GeoDataFrame([p])\n",
    "outline.columns = [\"geometry\"]\n",
    "\n",
    "def plot_data(hb, progress, df, weights, save_as=None):\n",
    "    \"\"\" \n",
    "        Plot the hour (hb), \n",
    "        with a given progress percentage (1-100), \n",
    "        the data for this hour (df)\n",
    "        and the weights (weights)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Depending on the number of mentions m (already calculated, parameter weights), \n",
    "    # multiply each location to exist m times\n",
    "    # Otherwise the kdeplot does not look as good\n",
    "    weighted_df = [[item] * int(weights[idx]+1) for idx, item in enumerate(df.geometry)]\n",
    "    weighted_df = [b for a in weighted_df for b in a]\n",
    "    weighted_df = gpd.GeoDataFrame(weighted_df)\n",
    "    weighted_df.columns = [\"geometry\"]\n",
    "    \n",
    "    \n",
    "    fig, axs = plt.subplots(2, figsize=(20, 10), gridspec_kw={'height_ratios': [100, 1]})\n",
    "    # Plot the kdeplot\n",
    "    geoplot.kdeplot(weighted_df,\n",
    "                    ax=axs[0],\n",
    "                    shade=True,\n",
    "                    # thresh=0.05,\n",
    "                    n_levels=30,\n",
    "                    # thresh=0.0,\n",
    "                    extent=(-180, -90, 180, 90),\n",
    "                    cmap='viridis')\n",
    "    \n",
    "    # Plot the outline \n",
    "    geoplot.polyplot(world, ax=axs[0], zorder=1, edgecolor='white')\n",
    "    \n",
    "    # Plot the mentioned points, with their hue on a log scale (otherwise not as clearly visible)\n",
    "    geoplot.pointplot(df, hue=\"count_log\", scale=\"count_log\", extent=(-180, -90, 180, 90), ax=axs[0], cmap='Wistia')\n",
    "    \n",
    "    # Plot the dummy outline (see above)\n",
    "    outline.boundary.plot(ax=axs[0], zorder=0, facecolor='#440154')\n",
    "    \n",
    "    # Plot top locations\n",
    "    t, c = get_top_10_locations(data_hb)\n",
    "    c = c[::-1]\n",
    "    t = t[::-1]\n",
    "    for idx, item in enumerate(t):\n",
    "        axs[0].text(-180, -70+idx*4, \"{:4} {}\".format(c[idx], item), fontsize=14, color=\"white\")\n",
    "    \n",
    "    # Plot watermark / link\n",
    "    axs[0].text(-35, -87, r'Data from \\textbf{www.mapnews.io}', fontsize=16, color=\"white\")    \n",
    "    \n",
    "    # Plot progress\n",
    "    # Text\n",
    "    time_now = hb.strftime(\"%Y-%m-%d %H:%M UTC\")\n",
    "    axs[1].text(50 - 7.5, 0.85, \"{:^30}\".format(time_now), fontsize=16, color=\"white\")\n",
    "    # Barplot\n",
    "    axs[1].barh([0], [100], color=\"#440154\")\n",
    "    axs[1].barh([0], [progress], color=\"white\")\n",
    "    of = 3.2\n",
    "    axs[1].set_xlim([-of + 0, 100 + of])\n",
    "    axs[1].axis('off')\n",
    "    \n",
    "    # Remove space & set background!\n",
    "    fig.tight_layout()\n",
    "    fig.patch.set_facecolor('#440154')\n",
    "    \n",
    "    # If the plot is to be saved, save it.\n",
    "    if save_as:\n",
    "        fig = plt.gcf()\n",
    "        plt.savefig(\"{}.png\".format(save_as), dpi=200, bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all articles\n",
    "dfs = []\n",
    "for path in news_files_paths:\n",
    "    data = read_file(path)\n",
    "    dfs += [parse_data(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinate and sort by hours\n",
    "data = pd.concat(dfs)\n",
    "data = data.sort_values(\"date_hour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the first occurence of the news article\n",
    "data = data.drop_duplicates(subset=['title', 'name'])\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each news article has a lifetime of 24 hours\n",
    "TIME_UNTIL_REMOVE_HRS = 24\n",
    "\n",
    "# Start and end times of when to show this particular news item\n",
    "data[\"date_start\"] = pd.to_datetime(data.date.dt.strftime(\"%Y-%m-%d %H\"))\n",
    "data[\"date_end\"] = data[\"date_start\"] + pd.Timedelta(hours=TIME_UNTIL_REMOVE_HRS)\n",
    "# For nicer plots\n",
    "data[\"count_log\"] = np.log(data[\"count\"]) * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series from the start to the end of the data\n",
    "block_size = 1 #hours\n",
    "delta_in_days = (data.date.max().date() - data.date.min().date()).days + 1\n",
    "hour_blocks = pd.date_range(data.date.min().date(), periods=delta_in_days*(24/block_size), freq='{}H'.format(block_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start only from the 72th hour block \n",
    "hour_blocks_selected = hour_blocks[72:]\n",
    "max_idx = len(hour_blocks_selected)\n",
    "for idx, hb in enumerate(hour_blocks_selected):\n",
    "    data_hb = data[(hb >= data.date_start) & (hb <= data.date_end)]\n",
    "    \n",
    "    # print(\"-> {} ({}) \".format(hb, idx), len(data_hb))\n",
    "    print(\"{}\".format(idx), end=\" \")\n",
    "    \n",
    "    if data_hb.shape[0] == 0:\n",
    "        continue\n",
    "    \n",
    "    # Calculate weights \n",
    "    hours_elapsed_since_break = (hb - data_hb.date_start) / np.timedelta64(1, 'h')\n",
    "    weights = (TIME_UNTIL_REMOVE_HRS - hours_elapsed_since_break).values\n",
    "    weights[weights >= 20] = ((24 - weights[weights >= 20])*6)\n",
    "    # Plot\n",
    "    progress = idx/max_idx * 100\n",
    "    plot_data(hb, progress, data_hb, weights, save_as=\"Plots/{}\".format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
